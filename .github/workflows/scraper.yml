name: Auto Job Scraper

on:
  schedule:
    # Runs every 30 minutes
    - cron: '*/30 * * * *'
  
  # Allows manual trigger from GitHub Actions tab
  workflow_dispatch:

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests
    
    - name: Load previous posted jobs
      run: |
        if [ -f posted_jobs.json ]; then
          echo "Found previous posted jobs file"
        else
          echo "[]" > posted_jobs.json
        fi
    
    - name: Run job scraper
      env:
        WP_URL: ${{ secrets.WP_URL }}
        WP_USERNAME: ${{ secrets.WP_USERNAME }}
        WP_APP_PASSWORD: ${{ secrets.WP_APP_PASSWORD }}
        ADZUNA_APP_ID: ${{ secrets.ADZUNA_APP_ID }}
        ADZUNA_API_KEY: ${{ secrets.ADZUNA_API_KEY }}
        JSEARCH_API_KEY: ${{ secrets.JSEARCH_API_KEY }}
      run: |
        python job_scraper.py
    
    - name: Commit posted jobs tracker
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add posted_jobs.json
        git diff --quiet && git diff --staged --quiet || git commit -m "Update posted jobs tracker [skip ci]"
        git push
```

### **Step 4: Commit the File**

1. Scroll down to **"Commit new file"**
2. Leave the default commit message: `Create scraper.yml`
3. Click **"Commit new file"** (green button)

---

## ✅ **Step 5: Verify the Files Exist**

After committing, you should see in your repository:
```
techjobs360-scraper/
├── .github/
│   └── workflows/
│       └── scraper.yml          ✅ (you just created this)
├── job_scraper.py               ✅ (check if this exists)
└── posted_jobs.json             ✅ (check if this exists)
